{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân tích cảm xúc với LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong assignment này, chúng ta sẽ dùng mạng LSTM để giải quyết bài toán phân tích cảm xúc (Sentiment Analysis) trên tập dữ liệu văn bản. Nếu nhìn theo kiểu black box, đầu vào của bài toán là một câu hoặc đoạn văn bản và đầu ra là trạng thái tích cực, tiêu cực hay trung hoà (positive - negative - neutral). Trong phạm vi của assignment này, chúng ta chỉ quan tâm đến hai trạng thái cảm xúc là positive và negative.\n",
    "\n",
    "![caption](Images/input_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Góc nhìn Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu như chúng ta giữ nguyên định dạng đầu vào là chuỗi ký tự thì rất khó để thực hiện các thao tác biến đổi như tích vô hướng (dot product) hoặc các thuật toán trên mạng neural network như backpropagation. Thay vì dữ liệu đầu vào là một chuỗi, chúng ta cần chuyển đổi các từ trong tập từ điển sang dạng vector số học trong đó có thể thực hiện được các phép toán nêu trên.\n",
    "\n",
    "![caption](Images/word2vec.png)\n",
    "\n",
    "Trong hình minh hoạ ở trên, ta có thể hình dung dữ liệu đầu vào của thuật toán phân tích cảm xúc là một ma trận 16 x D chiều. Trong đó 16 là số lượng từ trong câu và D là số chiều của không gian vector để biểu diễn từ. Để ánh xạ từ một từ sang một vector, chúng ta sử dụng ma trận word embedding như đã thực hiện trong bài Lab 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tập dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong assignment này, chúng tôi sử dụng tập dữ liệu review trên trang Foody với khoảng 30,000 mẫu được gán nhãn. Trong đó có 15,000 mẫu positive và 15,000 mẫu negative. Nguồn: https://streetcodevn.com/blog/dataset. Tập dữ liệu này đã được đính kèm trong thư mục của assignment 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các bước để huấn luyện trên mạng RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có 5 bước chính để giải quyết bài toán phân tích cảm xúc trong văn bản:\n",
    "\n",
    "    1) Huấn luyện một mô hình phát sinh ra vector từ (như mô hình Word2Vec) hoặc tải lên các vector từ tiền huấn luyện.\n",
    "    2) Tạo ma trận ID cho tập dữ liệu huấn luyện\n",
    "    3) Tạo mô hình RNN với các đơn vị LSTM, sử dụng tensorflow\n",
    "    4) Huấn luyện mô hình RNN với dữ liệu ma trận đã tạo ở bước 2\n",
    "    5) Đánh giá mô hình đã huấn luyện với tập test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load tập từ vựng và ma trận word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, để có thể biến đổi một từ thành một vector, chúng ta sử dụng mô hình đã được huấn luyện trước đó (pretrained model). Mô hình đã train trước đó cho tiếng Việt được lấy ở đây: https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.vi.300.vec.gz\n",
    "\n",
    "Tuy nhiên, số lượng từ vựng tiếng Việt được huấn luyện rất lớn, khoảng 2M từ. Mỗi từ được biểu diễn dưới dạng một vector 300 chiều. Với kích thước gốc của ma trận word embedding như vậy sẽ gây khó khăn cho việc load dữ liệu cũng như đưa vào thư viện tensorflow để huấn luyện nên chúng tôi đã tối giản lại với số lượng từ tối thiểu để có thể chạy được trên tập dữ liệu review về đồ ăn của Foody.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified vocabulary loaded!\n",
      "Word embedding matrix loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# LƯU Ý: CẦN PHẢI CHỈNH LẠI ĐƯỜNG DẪN NÀY THÀNH THƯ MỤC CHỨA CÁC FILE ASSIGNMENT3\n",
    "# CHỮ 'drive' có nghĩa là thư mục mặc định của Google drive\n",
    "currentDir = '.'\n",
    "\n",
    "wordsList = np.load(os.path.join(currentDir, 'wordsList.npy'))\n",
    "print('Simplified vocabulary loaded!')\n",
    "wordsList = wordsList.tolist()\n",
    "#wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load(os.path.join(currentDir, 'wordVectors.npy'))\n",
    "wordVectors = np.float32(wordVectors)\n",
    "print ('Word embedding matrix loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để chắc chắn mọi dữ liệu được load lên một cách chính xác, chúng ta cần kiểm tra xem số lượng từ trong từ điển rút gọn và số chiều của ma trận word embedding có khớp với nhau hay không? Trong trường hợp này số từ mà chúng tôi giữ lại là 19,899 và số chiều trong không gian biểu diễn là 300 chiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary:  19899\n",
      "Size of the word embedding matrix:  (19899, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Size of the vocabulary: ', len(wordsList))\n",
    "print('Size of the word embedding matrix: ', wordVectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec trên một từ đơn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để có thể xác định được vector biểu diễn của một từ tiếng Việt. Đầu tiên chúng ta sẽ xác định xem vị trí của từ đó trong wordsList. Sau đó lấy vector ở dòng tương ứng trên trên ma trận wordVectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of `ngon` in wordsList:  14598\n",
      "Vector representation of `ngon` is:  [-2.040e-02 -9.800e-03  2.290e-01 -3.770e-02  5.430e-02 -2.680e-02\n",
      "  2.190e-02 -6.290e-02 -2.200e-02 -1.010e-02  8.300e-03 -8.810e-02\n",
      " -3.630e-02  7.820e-02 -7.780e-02 -4.930e-02 -6.600e-03 -1.026e-01\n",
      " -1.040e-02  5.380e-02  4.100e-02  6.530e-02 -2.770e-02 -6.340e-02\n",
      "  2.270e-02  4.420e-02  3.340e-02 -4.960e-02  8.290e-02 -3.990e-02\n",
      "  3.750e-02  1.800e-02 -1.115e-01 -7.200e-02 -5.060e-02 -1.051e-01\n",
      " -4.560e-02 -1.765e-01 -3.300e-02 -6.800e-03  5.580e-02 -4.180e-02\n",
      "  4.380e-02  4.940e-02  7.400e-03  4.020e-02 -8.850e-02 -9.840e-02\n",
      " -5.210e-02 -5.500e-03  3.730e-02 -8.460e-02 -6.910e-02 -4.980e-02\n",
      " -3.910e-02 -4.980e-02 -8.690e-02  6.100e-03 -5.360e-02 -3.800e-03\n",
      "  1.162e-01 -4.160e-02  5.000e-03 -7.240e-02 -3.320e-02  1.800e-02\n",
      "  1.200e-02 -4.420e-02  1.350e-01  6.580e-02 -1.110e-02  1.960e-02\n",
      "  1.750e-02  2.010e-02  2.200e-03  1.810e-01 -6.610e-02 -6.860e-02\n",
      " -4.690e-02  7.890e-02  6.880e-02 -5.320e-02  2.770e-02  5.710e-02\n",
      " -1.183e-01  4.170e-02 -8.200e-02 -5.900e-02  8.790e-02  9.640e-02\n",
      "  6.000e-02  1.330e-02 -3.640e-02 -1.110e-02 -2.200e-02  1.770e-02\n",
      " -3.420e-02 -4.020e-02  3.590e-02  1.467e-01 -1.730e-02 -2.650e-02\n",
      "  6.400e-02  7.000e-03 -3.930e-02 -5.540e-02 -4.360e-02  8.000e-02\n",
      " -5.480e-02  3.840e-02 -8.330e-02  7.070e-02 -9.100e-03  2.480e-02\n",
      " -7.500e-03  3.030e-02 -6.600e-03 -9.800e-03  7.640e-02 -9.300e-03\n",
      "  2.330e-02 -2.000e-02  5.970e-02 -2.680e-02 -2.000e-02 -9.700e-03\n",
      " -5.310e-02 -9.820e-02 -2.570e-02  2.400e-02 -5.860e-02  1.820e-02\n",
      " -4.280e-02  9.580e-02  3.400e-02 -7.100e-03 -6.200e-03  1.239e-01\n",
      "  4.830e-02 -4.050e-02  4.810e-02 -1.093e-01  1.540e-02 -3.860e-02\n",
      "  1.250e-01 -7.950e-02  6.800e-03  7.420e-02  5.500e-02 -4.130e-02\n",
      " -2.090e-02 -2.250e-02  3.960e-02 -1.086e-01 -2.200e-02 -4.420e-02\n",
      "  1.965e-01 -2.260e-02  1.196e-01  1.200e-02  1.199e-01 -8.700e-03\n",
      "  4.260e-02  3.460e-02 -3.780e-02  1.951e-01 -9.300e-03 -6.260e-02\n",
      "  2.730e-02  7.340e-02  1.800e-03  5.080e-02 -3.470e-02 -9.680e-02\n",
      " -1.278e-01  3.790e-02  6.920e-02 -5.300e-02 -1.020e-01  1.076e-01\n",
      "  1.361e-01 -7.390e-02  9.650e-02 -2.250e-02  1.597e-01 -2.750e-02\n",
      " -4.200e-03  1.032e-01 -4.910e-02 -7.100e-03 -1.840e-02  7.240e-02\n",
      " -2.040e-02 -5.010e-02 -2.000e-04 -4.190e-02 -5.720e-02 -8.000e-03\n",
      "  9.780e-02 -7.130e-02 -6.070e-02 -1.740e-02 -1.290e-02  8.250e-02\n",
      "  6.600e-03 -2.250e-02 -5.100e-02  6.520e-02 -1.870e-02  5.790e-02\n",
      "  1.814e-01 -1.220e-01  4.770e-02  5.300e-02 -4.230e-02  2.139e-01\n",
      " -9.100e-03  1.314e-01 -3.600e-02 -3.780e-02  4.260e-02  3.000e-04\n",
      " -8.200e-02  1.570e-02 -1.380e-02  3.420e-02 -2.080e-02  1.790e-01\n",
      "  5.240e-02 -1.464e-01  6.330e-02  5.620e-02  2.000e-03 -6.490e-02\n",
      "  4.000e-04 -1.310e-02  1.020e-02  6.380e-02 -1.190e-02  2.440e-02\n",
      " -1.430e-02  1.027e-01  3.200e-03 -1.120e-02  8.270e-02  5.690e-02\n",
      "  2.740e-02 -9.800e-02 -3.150e-02 -9.750e-02 -1.660e-02  7.640e-02\n",
      " -4.960e-02 -7.940e-02  1.177e-01 -2.800e-03  6.860e-02 -5.930e-02\n",
      "  7.470e-02  5.790e-02  3.450e-02  5.550e-02 -3.380e-02  1.292e-01\n",
      "  3.840e-02  7.440e-02 -6.450e-02  2.470e-02 -1.810e-02  9.840e-02\n",
      " -1.329e-01 -6.380e-02 -8.360e-02 -3.580e-02  6.500e-03  8.240e-02\n",
      " -6.140e-02 -1.116e-01  2.310e-02  8.070e-02 -1.670e-02  4.150e-02\n",
      " -8.210e-02  6.290e-02 -5.580e-02  2.600e-03 -2.170e-02  3.200e-03\n",
      " -5.500e-03  6.040e-02  2.990e-02 -1.061e-01  5.200e-02  7.560e-02\n",
      "  6.250e-02  1.007e-01 -1.080e-01 -5.420e-02 -6.620e-02  6.080e-02]\n"
     ]
    }
   ],
   "source": [
    "ngon_idx = wordsList.index('ngon')\n",
    "print('Index of `ngon` in wordsList: ', ngon_idx)\n",
    "ngon_vec = wordVectors[ngon_idx]\n",
    "print('Vector representation of `ngon` is: ', ngon_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo 3.1: Word2Vec để biểu diễn một đoạn văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nâng cấp hơn so với phiên bản Word2Vec cho từ đơn, phần này chúng ta sẽ biểu diễn một câu dưới dạng một ma trận gồm các vector biểu diễn của từng từ chồng lên nhau.\n",
    "\n",
    "Ví dụ như chúng ta muốn biểu diễn câu \"Món này ăn hoài không biết chán\". Đầu tiên, với mỗi từ trong câu ta sẽ tìm chỉ số tương ứng trong từ điển và lưu vào vector đặt tên là 'sentenceIndexes'. Sau đó, chúng ta có thể sử dụng hàm tra cứu ma trận word embedding của thư viện Tensorflow tf.nn.embedding_lookup để tra các vector tại các chỉ số trong 'sentenceIndexes'. Như vậy nếu chúng ta sử dụng tối đa 10 từ để lưu trữ cho một câu thì ma trận biểu diễn cho câu sẽ là một ma trận kích thước 10 x 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/embedding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "Row index for each word:  [  119  8136  4884 18791 16614 15951  3371     0     0     0]\n",
      "Sentence representation of word vectors:\n",
      "(10, 300)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "maxSeqLength = 10   #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "sentenceIndexes = np.zeros((maxSeqLength), dtype='int32')\n",
    "\n",
    "# TODO 3.1: Gán chỉ số của các từ trong câu và 'sentenceIndexes'\n",
    "sentence = 'Món này ăn hoài không biết chán'\n",
    "for i, word in enumerate(sentence.split()):\n",
    "    word = word.lower()\n",
    "    if word in wordsList:\n",
    "        sentenceIndexes[i] = wordsList.index(word)\n",
    "\n",
    "# Các chỉ số 7, 8, 9 của sentenceIndexes  vẫn được gán bằng 0 như cũ\n",
    "print(sentenceIndexes.shape)\n",
    "print('Row index for each word: ', sentenceIndexes)\n",
    "\n",
    "# Ma trận biểu diễn:\n",
    "print('Sentence representation of word vectors:')\n",
    "print(tf.nn.embedding_lookup(wordVectors,sentenceIndexes).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu như thực hiện đúng thì vector 'sentenceIndexes' sẽ có giá trị là: [119, 8136, 4884, 18791, 16614, 15951, 3371, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Khảo sát tập dữ liệu huấn luyện và tạo ma trận ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong assignment 3, chúng tôi sử dụng tập dữ liệu lấy từ trang web Foody trên miền dữ liệu liên quan đến ẩm thực. Tập dữ liệu bao gôm 15.000 review tích cực đặt trong thư mục 'positiveReviews' và 15.000 review tiêu cực đặt trong thư mục 'negativeReviews'. Do khối lượng dữ liệu lớn, nếu chúng ta chọn số lượng từ tối đa (maxSeqLength) quá cao thì sẽ bị lãng phí khi biểu diễn ở những câu review quá ngắn. Ngược lại, nếu sử dụng số lượng từ tối đa quá ít thì sẽ bị bỏ lỡ những từ quan trọng giúp cho việc phân tích cảm xúc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n",
      "Negative files finished\n",
      "The total number of files is 30000\n",
      "The total number of words in the files is 1770824\n",
      "The average number of words in the files is 59.02746666666667\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "positiveFiles = ['positiveReviews/' + f for f in listdir('positiveReviews/') if isfile(join('positiveReviews/', f))]\n",
    "negativeFiles = ['negativeReviews/' + f for f in listdir('negativeReviews/') if isfile(join('negativeReviews/', f))]\n",
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)  \n",
    "print('Negative files finished')\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể sử dụng thư viện Matplot để minh hoạ phân bố về chiều dài của các câu review trong tập dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa trên biểu đồ histogram ở trên chúng ta có thể thấy là 180 là kết quả tương đối hợp lý. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để có cảm nhận rõ hơn về dữ liệu, chúng ta có thể hiển thị một số review bất kỳ như sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A positive sentence: \n",
      "Minh đến đây là vì nhân_viên ở đây . Lúc mình đến thì tối muộn rồi mà khách vẫn đông người mà toàn mấy bạn nữ ( chắc giống mình ) . Mình gọi trà matcha óc chó và cực_kì hài_lòng . Vì mình đến lúc đông khách nên cảm_giác hơi bí nhưng không_gian đẹp và nhân_viên thì trên cả tuyệt_vời . Từ nhân_viên gửi xe đến dọn_dẹp hay pha_chế đều thân_thiện , dễ_thương .\n",
      "\n",
      "A negative sentence: \n",
      "Điạ điễm mình yêu thíc và thường_xuyên ghé . Stố ngon li bự , có trái_cây đễ lên trên nên nhìn đẹp và hấp_dẫn , mình uống thường mix các loại vs nhau nên lúc_nào cũng thấy ngon 😙 giá_cả cũng đc , có Wi-Fi nhưng hơi yếu . Chỉ ghét là giữ xe 10k , lễ lộc là 20k 😫 mua về thì chỗ_đứng hơi hẹp , ngồi uống cũng v hơi chật do ngồi sát 2bên hẽm đễ chừa đg cho xe và ng ra_vào . Nằm trong khu Bùi viện lên lúc_nào cũng tấp_nập đông vui 👍\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('A positive sentence: ')\n",
    "fname = positiveFiles[3] # Randomly select a positive file to view\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    for lines in f:\n",
    "        print(lines)\n",
    "\n",
    "print('A negative sentence: ')\n",
    "fname = negativeFiles[10] # Randomly select a negative file to view\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    for lines in f:\n",
    "        print(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn hoá văn bản và tách từ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để tiết kiệm công sức và cũng nằm ngoài phạm vi của khoá học, chúng tôi đã chuẩn bị sẵn tập dữ liệu đã được tách từ. Giữa hai từ có thể ghép lại để tạo thành một khái niệm mới chúng tôi sử dụng ký tự '_' để nối các từ đó. Ví dụ: 'sinh_viên', 'sinh_học'.\n",
    "\n",
    "Chúng tôi chuẩn bị sẵn các hàm chuẩn hoá văn bản nhằm loại bỏ các ký tự đặc biệt. Tham khảo ở hàm 'cleanSentences'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^\\w0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ chúng ta sẽ biểu diễn 30.000 review dưới dạng các chỉ số của các từ. Tập dữ liệu positive và negative sẽ được tính hợp lại thành một ma trận 30000x180. Trong đó 30000 là số lượng review và 180 là số lượng từ tối đa cho một câu. Do bước chuẩn bị này tốn khá nhiều tài nguyên tính toán nên sau khi tính toán xong, chúng ta sẽ lưu lại để sử dụng cho những lần chạy thí nghiệm sau. Ma trận lưu trữ các chỉ số này là: 'ids'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo 3.2: xác định chỉ số của từng từ trong review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong phần này chúng ta sẽ tiến hành tra cứu từng từ trong review, sau đó gán vào ma trận 'ids'. Trong đó chỉ số dòng của ma trận tương ứng với file review, chỉ số cột của ma trận tương ứng với một từ của review. Trường hợp từ nào không có trong tập từ điển thì ta sẽ gán bằng chỉ số của từ 'UNK' (unknow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positiveReviews/27034.txt',\n",
       " 'positiveReviews/30572.txt',\n",
       " 'positiveReviews/414.txt',\n",
       " 'positiveReviews/3350.txt',\n",
       " 'positiveReviews/4288.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positiveFiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files are indexed!\n",
      "Negative files are indexed!\n"
     ]
    }
   ],
   "source": [
    "ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "nFiles = 0\n",
    "# Index of Unknow word\n",
    "unk_idx = wordsList.index('UNK')\n",
    "\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding=\"utf-8\") as f:\n",
    "        nIndexes = 0\n",
    "        lines=f.readlines()\n",
    "        flag_max = False\n",
    "        for line in lines:\n",
    "            cleanedLine = cleanSentences(line)\n",
    "            split = cleanedLine.split()\n",
    "        \n",
    "            for word in split:\n",
    "                # TODO 3.2: Nếu 'word' thuộc tập 'wordsList' thì gán chỉ số của 'word' vào ma trận ids\n",
    "                if word in wordsList:\n",
    "                    ids[nFiles][nIndexes] = wordsList.index(word)\n",
    "                else:\n",
    "                    ids[nFiles][nIndexes] = unk_idx\n",
    "                # Ngược lại: gán 'unk_idx' vào ma trận ids\n",
    "            \n",
    "                nIndexes = nIndexes + 1\n",
    "                if nIndexes >= maxSeqLength:\n",
    "                    flag_max = True\n",
    "                    break\n",
    "            if flag_max:\n",
    "                break\n",
    "        nFiles = nFiles + 1 \n",
    "\n",
    "print('Positive files are indexed!')\n",
    "for pf in negativeFiles:\n",
    "    with open(pf, \"r\", encoding=\"utf-8\") as f:\n",
    "        nIndexes = 0\n",
    "        lines=f.readlines()\n",
    "        flag_max = False\n",
    "        for line in lines:\n",
    "            cleanedLine = cleanSentences(line)\n",
    "            split = cleanedLine.split()\n",
    "        \n",
    "            for word in split:\n",
    "                # TODO 3.2: Nếu 'word' thuộc tập 'wordsList' thì gán chỉ số của 'word' vào ma trận ids\n",
    "                if word in wordsList:\n",
    "                    ids[nFiles][nIndexes] = wordsList.index(word)\n",
    "                else:\n",
    "                    ids[nFiles][nIndexes] = unk_idx\n",
    "                # Ngược lại: gán 'unk_idx' vào ma trận ids\n",
    "            \n",
    "                nIndexes = nIndexes + 1\n",
    "                if nIndexes >= maxSeqLength:\n",
    "                    flag_max = True\n",
    "                    break\n",
    "            if flag_max:\n",
    "                break\n",
    "        nFiles = nFiles + 1\n",
    "\n",
    "print('Negative files are indexed!')\n",
    "# Save ids Matrix for future uses.\n",
    "np.save(os.path.join(currentDir,'idsMatrix.npy'), ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word indexes of the first review:  [11975  8136 17108 13863  5596 14855  5596   799 10774  4884 11975 14753\n",
      " 14794  1825 10774 12615 14855  4711  8031   880  2616  8262 10630  4558\n",
      "  5446  2465  3364  4639  6708  6521 11440 17292  4135  4957 17330 12145\n",
      " 18393 15387 16760 14017 16521  6244 10231  7692 11440 14341   547 14475\n",
      "  2223  7087 18393  7424 18655  9673 11068 14595 10139 11440 19646 10453\n",
      " 11975  4558 15444 18407 19363 16624  3364 14017 16521  8884  1906 17821\n",
      " 15522   547  1868 12145 18503  1906  6512  9704  2997 11068 14598 15570\n",
      "  5596 13258  4884 16995  6512  9704  6874 12990 11047 10346 17162  6915\n",
      " 18584  4884 17130  2611 18503 16995  4711 12990 12145  1047  1731 13315\n",
      "  8880 14017 16521 16807 19261 16346  6512  9704  6512  9704 17572  6874\n",
      "  8231  1368 19193  9673  4682  8231  1238  4558   294  5596 11440 16812\n",
      "  1450  2451  1807   495  1346  1807 16995  6512  9704  8548  5596 13255\n",
      "  7836 15605  5767 17636  1868 11966  5013  4236 18655   119  4884 10009\n",
      " 15341  1074  2789 17821 14598 18503   547 14017 16521  5596  5074 14341\n",
      "  2345  8591 15213  3167  5767  8591 15213 12413 15213  4964  6365 14855]\n"
     ]
    }
   ],
   "source": [
    "# LƯU Ý: Bước thực hiện trên tương đối mất thời gian.\n",
    "# Trường hợp đã tính toán và lưu ma trận 'ids' rồi thì ta có thể load lên để sử dụng luôn\n",
    "ids = np.load(os.path.join(currentDir,'idsMatrix.npy'))\n",
    "print('Word indexes of the first review: ', ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quán này gần nhà mình nên mình hay đến ăn quán mở_cửa từ sáng đến tối nên hk sợ canh giờ_giấc không_gian thoáng có máy_lạnh mát lắm lun khá yên_tĩnh đi đông nói_chuyện ồn quá thì hơi kì vì ở đây đa_số ng ta đi uống cafe làm_việc học bài hơi yên_lặng trang_trí lịch_sự cực sạch_sẽ nếu đi chiều chiều_tối quán có mở nhạc_nhẹ nghe phê lắm ở đây ngoài bán kem và cafe ra thì còn bán mỳ ý nữa cực ngon nhé mình thường ăn phần mỳ ý bò phô_mai dành cho các bạn thích ăn béo_béo 42k còn phần hk phô_mai thì rẻ hơn giá_cả phù_hợp ở đây menu đủ kiểu mỳ ý mỳ ý gà bò phục_vụ tốt thân_thiện lịch_sự thời_gian phục_vụ nhanh có kỳ mình đi zs bạn_bè tổng_cộng 6 đứa kêu 6 phần mỳ ý tụi mình ngồi nc tí là đem ra liền à cách trang_trí món ăn bắt_mắt trà đá free kem ngon còn cafe ở đây mình chưa uống vị_trí trong hẻm nói là trong hẻm chứ hẻm cũng bự nên '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ''\n",
    "for w in ids[0]:\n",
    "  s += wordsList[w]\n",
    "  s += ' '\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu như quá trình chuyển từ câu dạng văn bảng sang vector các chỉ số trong từ điển ở trên đúng thì ids[0] sẽ nhận giá trị: [19898  1906  4454  5284 10661 11694 11994 18784 18569 18619 13174  9821 ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xây dựng hàm lấy dữ liệu train và test theo từng batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dưới đây chúng tôi xây dựng các hàm để lấy dữ liệu train và test theo từng batch. Bạn hãy giải thích tại sao lại có các con số 13999, 14999, 15999, 29999 nhé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getFullData():\n",
    "    train_y = []\n",
    "    test_y = []\n",
    "    train_x = np.zeros([28000, maxSeqLength])\n",
    "    test_x = np.zeros([2000, maxSeqLength])\n",
    "    train_num = 0\n",
    "    test_num = 0\n",
    "    \n",
    "    for i in range(30000):    \n",
    "        if i < 14000:\n",
    "            train_y.append(1)\n",
    "            train_x[train_num] = ids[i:i+1]\n",
    "            train_num += 1\n",
    "            \n",
    "        elif i >= 14000 and i <15000:\n",
    "            test_y.append(1)\n",
    "            test_x[test_num] = ids[i:i+1]\n",
    "            test_num += 1\n",
    "            \n",
    "        elif i >= 15000 and i < 16000:\n",
    "            test_y.append(0)\n",
    "            test_x[test_num] = ids[i:i+1]\n",
    "            test_num += 1\n",
    "            \n",
    "        elif i >= 16000:\n",
    "            train_y.append(0)\n",
    "            train_x[train_num] = ids[i:i+1]\n",
    "            train_num += 1\n",
    "    return train_x, np.array(train_y), test_x, np.array(test_y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Xây dựng RNN Model với Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên chúng tôi sẽ khởi tạo các tham số cho mô hình mạng RNN với các cell là các LSTM. Kiến trúc mạng ở đây bao gồm 128 đơn vị cho mỗi lớp, số lượng layer là 2, số lượng phân lớp là 2 và số vòng lặp khi huấn luyện là 30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize paramters\n",
    "numDimensions = 300\n",
    "batchSize = 64\n",
    "lstmUnits = 128\n",
    "nLayers = 2\n",
    "numClasses = 2\n",
    "iterations = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để lưu trữ dữ liệu input và ouput, chúng ta sẽ sử dụng hai kiểu dữ liệu placeholder. Một trong những điều quan trọng nhất khi khởi tạo các biến input và output này là xác định kích thước của các tensor. Mỗi output của mạng (hay còn gọi là label) sẽ là một vector one hot với hai giá trị tương ứng với hai loại cảm xúc: [1, 0] cho positive và [0, 1] cho negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/data_batch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo 3.3: Xác định input và output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khởi tạo hai biến 'inputs' và 'labels' bằng kiểu placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 180)\n",
      "(28000,)\n",
      "(2000, 180)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "inputs, labels, test_inputs, test_labels = getFullData()\n",
    "\n",
    "train_index = np.arange(len(inputs))\n",
    "np.random.shuffle(train_index)\n",
    "inputs = inputs[train_index]\n",
    "labels = labels[train_index]\n",
    "inputs = tf.convert_to_tensor(inputs, dtype=tf.int32)\n",
    "labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "test_inputs = tf.convert_to_tensor(test_inputs, dtype=tf.int32)\n",
    "test_labels = tf.convert_to_tensor(test_labels, dtype=tf.float32)\n",
    "\n",
    "print(inputs.shape)\n",
    "print(labels.shape)\n",
    "print(test_inputs.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó tạo dữ liệu word vector từ khối dữ liệu đầu vào với ma trận word embedding. Nếu như quá trình khởi tạo đúng thì sẽ tạo ra các kiểu dữ liệu sau:\n",
    "labels --> Tensor(\"Placeholder:0\", shape=(64, 2), dtype=float32)\n",
    "inputs --> Tensor(\"Placeholder_1:0\", shape=(64, 10), dtype=int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/embedding_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy sau bước này chúng ta đã có dữ liệu để đưa vào mạng mạng các LSTM. Để khởi tạo một LSTM chúng ta sử dụng hàm tf.nn.rnn_cell.BasicLSTMCell. Hàm này cần tham số đầu vào là số lượng đơn vị muốn khởi tạo. Đây chính là một hyperparamter đã được khởi tạo trước đó.\n",
    "Để chống lại việc overfitting, chúng ta sử dụng lớp dropout. \n",
    "\n",
    "Để tăng tính phức tạp cho kiến trúc mạng chúng ta chồng các lớp LSTM lên nhau (Stack LSTM Layers). Trong trường hợp này chúng ta sử dụng 2 lớp LSTM. Việc chồng thêm các lớp LSTM sẽ giúp cho mô hình có khả năng nhớ nhiều thông tin hơn nhưng đồng thời cũng làm tăng số lượng tham số khi huấn luyện. Điều này cũng có nghĩa là sẽ làm tăng thời gian huấn luyện cũng như là cần thêm nhiều dữ liệu hơn.\n",
    "\n",
    "Cuối cùng là đưa toàn bộ dữ liệu đầu vào vào mạng các LSTM sử dụng hàm tf.nn.dynamic_rnn. Chi tiết kiến trúc mạng LSTM sử dụng cho bài tập này được mô tả trong hình sau:\n",
    "\n",
    "![caption](Images/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi ra khỏi mạng LSTM, biến outputs sẽ là một tensor có kích thước [batchSize x maxSeqLength x lstmUnits], cụ thể là [64 x 180 x 128]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó, chúng ta chỉ lấy dữ liệu ở LSTM cell cuối cùng và cho đi qua lớp kết nối đầy đủ để phân loại thành 2 trạng thái. Chỉ số của LSTM cell cuối cùng là 179 (do có 180 cell theo chiều ngang)  nên để có thể lấy được giá trị ta sẽ chuyển vị về tensor có kích thước [maxSeqLength x batchSize x lstmUnits] hay [180 x 64 x 128]. Sử dụng hàm tf.gather để lấy tensor thứ 179 có kích thước [64 x 128] bao gồm 64 mẫu vector 128 chiều. Vector 128 chiều này sẽ được đưa vào lớp fully connected để chuyển đổi về vector 2 chiều tương ứng với 2 trạng thái.\n",
    "\n",
    "Lớp kết nối đầy đủ bao gồm các bộ tham số 'weight' và 'bias' để thực hiện việc dự đoán kết quả. Bước này chính là tạo một lớp Fully Connected như trong sơ đồ kiến trúc mạng LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class twoLayerLSTM(tf.keras.Model):\n",
    "    def __init__(self, lstmUnits, wordVectors):\n",
    "        super(twoLayerLSTM, self).__init__()\n",
    "        self.wordVectors = wordVectors\n",
    "        self.lstmUnits = lstmUnits\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        x = tf.nn.embedding_lookup(self.wordVectors, input_tensor)\n",
    "        x = tf.keras.layers.LSTM(self.lstmUnits, return_sequences=True, dropout=0.2)(x)\n",
    "        x = tf.keras.layers.LSTM(self.lstmUnits, dropout=0.2)(x)\n",
    "        x = tf.keras.layers.Dense(32, activation='tanh')(x)\n",
    "        x = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "        return x\n",
    "\n",
    "    def model(self):\n",
    "        x = tf.keras.Input(shape=(180,), dtype=tf.int32)\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 180)]             0         \n",
      "_________________________________________________________________\n",
      "tf.compat.v1.nn.embedding_lo (None, 180, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 180, 16)           20288     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,977\n",
      "Trainable params: 22,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = twoLayerLSTM(lstmUnits, wordVectors).model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "%load_ext tensorboard\n",
    "\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5*28000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 30s 612ms/step - loss: 0.6230 - accuracy: 0.7034 - val_loss: 0.5365 - val_accuracy: 0.7479\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.5308 - accuracy: 0.7509 - val_loss: 0.4909 - val_accuracy: 0.7870\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.4812 - accuracy: 0.7805 - val_loss: 0.4425 - val_accuracy: 0.8002\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.4494 - accuracy: 0.7929 - val_loss: 0.4148 - val_accuracy: 0.8030\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.4241 - accuracy: 0.8074 - val_loss: 0.3935 - val_accuracy: 0.8320\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.4035 - accuracy: 0.8166 - val_loss: 0.3735 - val_accuracy: 0.8254\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.3869 - accuracy: 0.8195 - val_loss: 0.3672 - val_accuracy: 0.8207\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 28s 616ms/step - loss: 0.3872 - accuracy: 0.8181 - val_loss: 0.3583 - val_accuracy: 0.8313\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 29s 637ms/step - loss: 0.3801 - accuracy: 0.8240 - val_loss: 0.3564 - val_accuracy: 0.8286\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.3712 - accuracy: 0.8252 - val_loss: 0.3499 - val_accuracy: 0.8345\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 28s 633ms/step - loss: 0.3655 - accuracy: 0.8295 - val_loss: 0.3614 - val_accuracy: 0.8171\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 30s 661ms/step - loss: 0.3704 - accuracy: 0.8268 - val_loss: 0.3449 - val_accuracy: 0.8523\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.3481 - accuracy: 0.8441 - val_loss: 0.3371 - val_accuracy: 0.8480\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.3509 - accuracy: 0.8415 - val_loss: 0.3468 - val_accuracy: 0.8373\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.3569 - accuracy: 0.8391 - val_loss: 0.3390 - val_accuracy: 0.8477\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.3446 - accuracy: 0.8410 - val_loss: 0.3349 - val_accuracy: 0.8511\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 28s 633ms/step - loss: 0.3501 - accuracy: 0.8428 - val_loss: 0.3316 - val_accuracy: 0.8555\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 27s 613ms/step - loss: 0.3418 - accuracy: 0.8447 - val_loss: 0.3310 - val_accuracy: 0.8468\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 30s 671ms/step - loss: 0.3389 - accuracy: 0.8484 - val_loss: 0.3512 - val_accuracy: 0.8245\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 28s 628ms/step - loss: 0.3456 - accuracy: 0.8366 - val_loss: 0.3330 - val_accuracy: 0.8641\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 29s 641ms/step - loss: 0.3310 - accuracy: 0.8493 - val_loss: 0.3260 - val_accuracy: 0.8446\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 29s 652ms/step - loss: 0.3310 - accuracy: 0.8469 - val_loss: 0.3254 - val_accuracy: 0.8587\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 30s 658ms/step - loss: 0.3297 - accuracy: 0.8513 - val_loss: 0.3214 - val_accuracy: 0.8579\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 28s 630ms/step - loss: 0.3232 - accuracy: 0.8525 - val_loss: 0.3206 - val_accuracy: 0.8555\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 30s 662ms/step - loss: 0.3145 - accuracy: 0.8592 - val_loss: 0.3201 - val_accuracy: 0.8612\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 29s 634ms/step - loss: 0.3186 - accuracy: 0.8571 - val_loss: 0.3190 - val_accuracy: 0.8580\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 28s 633ms/step - loss: 0.3192 - accuracy: 0.8522 - val_loss: 0.3162 - val_accuracy: 0.8677\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 29s 649ms/step - loss: 0.3194 - accuracy: 0.8561 - val_loss: 0.3138 - val_accuracy: 0.8618\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 30s 664ms/step - loss: 0.3324 - accuracy: 0.8457 - val_loss: 0.3143 - val_accuracy: 0.8682\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 30s 665ms/step - loss: 0.3118 - accuracy: 0.8572 - val_loss: 0.3150 - val_accuracy: 0.8493\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 30s 666ms/step - loss: 0.3157 - accuracy: 0.8566 - val_loss: 0.3147 - val_accuracy: 0.8705\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 28s 629ms/step - loss: 0.3119 - accuracy: 0.8578 - val_loss: 0.3110 - val_accuracy: 0.8680\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 29s 635ms/step - loss: 0.2981 - accuracy: 0.8666 - val_loss: 0.3127 - val_accuracy: 0.8637\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 29s 645ms/step - loss: 0.3060 - accuracy: 0.8621 - val_loss: 0.3091 - val_accuracy: 0.8736\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 30s 665ms/step - loss: 0.3114 - accuracy: 0.8636 - val_loss: 0.3104 - val_accuracy: 0.8659\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 29s 654ms/step - loss: 0.2997 - accuracy: 0.8710 - val_loss: 0.3180 - val_accuracy: 0.8405\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 29s 641ms/step - loss: 0.3084 - accuracy: 0.8596 - val_loss: 0.3133 - val_accuracy: 0.8764\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 30s 664ms/step - loss: 0.2946 - accuracy: 0.8709 - val_loss: 0.3055 - val_accuracy: 0.8607\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 29s 641ms/step - loss: 0.2944 - accuracy: 0.8661 - val_loss: 0.3055 - val_accuracy: 0.8714\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 29s 654ms/step - loss: 0.2921 - accuracy: 0.8707 - val_loss: 0.3004 - val_accuracy: 0.8736\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 29s 644ms/step - loss: 0.2865 - accuracy: 0.8737 - val_loss: 0.3013 - val_accuracy: 0.8718\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.2860 - accuracy: 0.8726 - val_loss: 0.3044 - val_accuracy: 0.8718\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 28s 630ms/step - loss: 0.2832 - accuracy: 0.8750 - val_loss: 0.3380 - val_accuracy: 0.8486\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 29s 654ms/step - loss: 0.3083 - accuracy: 0.8611 - val_loss: 0.3006 - val_accuracy: 0.8764\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 29s 636ms/step - loss: 0.2837 - accuracy: 0.8742 - val_loss: 0.3217 - val_accuracy: 0.8546\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 30s 656ms/step - loss: 0.2927 - accuracy: 0.8724 - val_loss: 0.2963 - val_accuracy: 0.8741\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 29s 641ms/step - loss: 0.2823 - accuracy: 0.8771 - val_loss: 0.3051 - val_accuracy: 0.8788\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 29s 637ms/step - loss: 0.2806 - accuracy: 0.8809 - val_loss: 0.2979 - val_accuracy: 0.8766\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.2778 - accuracy: 0.8789 - val_loss: 0.2952 - val_accuracy: 0.8743\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 29s 641ms/step - loss: 0.2818 - accuracy: 0.8787 - val_loss: 0.2992 - val_accuracy: 0.8802\n"
     ]
    }
   ],
   "source": [
    "lstmUnits = 128\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x=inputs, y=labels, epochs=50, batch_size = 500, validation_split=0.2, shuffle=True, callbacks=[tensorboard_callback, cp_callback])\n",
    "model.save_weights(checkpoint_path.format(epoch=70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f1ec33664c4b9384\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f1ec33664c4b9384\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để xác định độ chính xác của hệ thống, ta đếm số lượng labels khớp với giá trị dự đoán (prediction). Sau đó tính độ chính xác bằng cách tính giá trị trung bình của các kết quả trả về đúng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng Tensorboard để visualize kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong quá trình huấn luyện, chương trình sẽ ghi log về độ lỗi và độ chính xác trên tập train vào thư mục 'tensorboard', lưu lại model sau mỗi 2000 vòng lặp ở thư mục 'models'. Việc huấn luyện trên 30,000 vòng lặp mất khoảng vài tiếng với GPU K80 được cung cấp bởi Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với mỗi vòng lặp, ta sẽ lấy ra một batch dữ liệu train để đưa vào mạng sử dụng `feed_dict`. với các tham số input và label là các placeholders. Bước huấn luyện này được lặp lại cho đến khi hết số lần cần huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 23ms/step - loss: 0.2960 - accuracy: 0.8795\n",
      "Restored model, accuracy: 87.95%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_inputs, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "63/63 [==============================] - 3s 24ms/step - loss: 0.2548 - accuracy: 0.8840\n",
      "Restored model, accuracy: 87.95%\n"
     ]
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "loaded_model = twoLayerLSTM(lstmUnits, wordVectors).model()\n",
    "loaded_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "loaded_model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 180)\n",
      "(2000,)\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.2960 - accuracy: 0.8795\n",
      "Restored model, accuracy: 87.95%\n"
     ]
    }
   ],
   "source": [
    "print(test_inputs.shape)\n",
    "print(test_labels.shape)\n",
    "loss, acc = loaded_model.evaluate(test_inputs, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load mô hình đã train và đánh giá mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thời gian huấn luyện mạng khá lâu, nên trong quá trình mạng đang được huấn luyện, ta sẽ lưu lại một số checkpoint. Để có thể test thử trên một checkpoint mới nhất ta sử dụng hàm tf.train.latest_checkpoint và truyền vào tên thư mục muốn lấy model mới nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó, với mỗi batch dữ liệu test, ta sẽ tiến hành test và tính độ chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo 3.6: Test mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do các bộ test được lấy ngẫu nhiên nên độ chính xác trong quá trình này cũng dao động từ 70% đến 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo 3.7: Viết hàm tổng hợp để dự đoán cảm xúc từ câu tiếng Việt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Câu cuối cùng này đòi hỏi đòi hỏi các bạn phải vận dụng tư duy tổng hợp để gom tất cả những bước đã thực hiện trước đó thành một quy trình hoàn chỉnh. Các bạn cần viết một hàm hoàn chỉnh với đầu vào là  một câu tiếng Việt cho trước, đầu ra là cho biết câu trên có cảm xúc tích cực hay tiêu cực."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = 'Món này ăn ngon mê ly luôn. Vị ngọt và thơm quá trời quá đất.'\n",
    "# TODO 3.7 Các bạn vận dụng toàn bộ quy trình đã thực hiện trước đó\n",
    "# để dự đoán xem câu này có cảm xúc tích cực hay tiêu cực\n",
    "# Câu này làm khá dài và có tính chất tổng hợp\n",
    "input_sentence = cleanSentences(input_sentence)\n",
    "s = input_sentence.split()\n",
    "indexes = np.zeros((1, maxSeqLength))\n",
    "for i,w in enumerate(s):\n",
    "    indexes[0][i] = wordsList.index(w)\n",
    "\n",
    "base_input = loaded_model.layers[0].input\n",
    "base_output = loaded_model.layers[4].output\n",
    "output = tf.keras.layers.Dense(1,activation='softmax')(base_output)\n",
    "model_ = tf.keras.Model(base_input, output)\n",
    "pred = model_.predict(indexes)\n",
    "#because i change the basic indexing above\n",
    "if pred == 1:\n",
    "    print(input_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kết luận"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy qua bài tập này, các bạn được ôn lại mô hình Word2Vec và sử dụng mô hình này để biểu diễn cho một văn bản. Sử dụng cách biểu diễn này để đưa vào mô hình RNN với nhiều đơn vị LSTM. Các bạn có thể thử nghiệm trên các cấu hình khác nhau bằng cách thay đổi các hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
